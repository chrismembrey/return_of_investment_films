{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b04a2fa",
   "metadata": {},
   "source": [
    "<h1> Predicting Film Return On Investment using TMDB and IMDB </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fca32d",
   "metadata": {},
   "source": [
    "<!--![](movie_collage.png) -->\n",
    "<img src = \"/Final_Movies/readmeregression_models_original.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd593e",
   "metadata": {},
   "source": [
    "The goal of this project was to see which pre film features, if any, had a hand in determining the films ending return on investment. A mix of classification and regression models were used to predict either profit/loss or the ROI (%).\n",
    "\n",
    "\n",
    "**Look at the full presentation here:**\n",
    "https://docs.google.com/presentation/d/143nyULpnLyzoOyFYceJvd_ZPJrZUcaTPaFIGM6gTPUE/edit#slide=id.p\n",
    "\n",
    "<!--**Visualise all the results results here:**\n",
    "https://github.com/franchiven/predicting-mental-health-reddit/blob/master/Visuals/All_Visuals.md\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8641955d",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Introduction](#introduction)\n",
    "- [Data Collection & Pre-Processing](#data-collection---pre-processing)\n",
    "- [Regression Modelling](#regression-modelling)\n",
    "- [Classification Modelling](#classification-modelling)\n",
    "- [Future Work](#future-work)\n",
    "- [Notebook Order](#notebook-order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b01427",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "According to Statista, the film industry generates roughly $10Bn a year in revenue. If its possible to find variables that can predict whether films will have high return of investment (ROI) or profit, a model can be created to help production companies come to a decision when giving a movie the green light or not.\n",
    "\n",
    "TMDB & IMDB are the most commonly used open-source websites where users can input infomation on films they have seen, the latter having infomation on ~7 Million titles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99c1505",
   "metadata": {},
   "source": [
    "## Data Collection & Pre-Processing\n",
    "TMDB was primarily used to collect the data since it had fast API calls using the tmdbsimple package. Conversly, although IMDB has more trustworthy infomation (amazon own IMDB and so the infomation given is consistenly monitored), the API calls were incredibly slow so only a few varibales could be collected using this API. Movies were only collected in a dataframe if they had both budgets and revenues greater than $0.\n",
    "\n",
    "\n",
    "The cleaning of these movies was acheived using the following steps:\n",
    "- Replacing null values with medians/means where appropriate \n",
    "- Removal of films with budgets and revenues less than $10,000\n",
    "- Dummification (categories)\n",
    "- Tokenisation (blurbs)\n",
    "- Count Vectorization (blurbs)\n",
    "- Data Binning\n",
    "- Standardisation (Continuous Features)\n",
    "- Hypothesis testing was used to determine if ROI means were significantly different between categories of variables, indicating whether the variable had predictive power for ROI\n",
    "\n",
    "NB - Initially, not all of the outliers could be removed since I needed a dataset as close to 10,000 observations as possible.\n",
    "\n",
    "After cleaning, around 9,500 datapoints were left and the following columns were used for ROI/profit prediction:\n",
    "\n",
    "- Directors (binary)\n",
    "- Composers (binary)\n",
    "- Runtime (continuous)\n",
    "- Genre (binary)\n",
    "- Day of week (binary)\n",
    "- Month released (binary)\n",
    "- Inflation budget (continuous)\n",
    "- Original language bins (binary)\n",
    "- Blurb length (continuous)\n",
    "- From collection (binary)\n",
    "- Blurb objectivity (continuous)\n",
    "- Blurb polarity (coninuous)\n",
    "- Unique genre pairing (binary)\n",
    "- Blurb words with top 100 roi means (binary)\n",
    "- Actors with more than 3 films to thier name (binary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615c9cc",
   "metadata": {},
   "source": [
    "## Regression Modelling\n",
    "Linear Regression, a Support Vector Machine (linear kernel only) and a Decision Tree Regression was used to predict the ROI of films. The best model was an ElasticNet linear regression model. \n",
    "\n",
    "<img src = \"/Final_Movies/readmeregression_models_original.png\" width=\"700\">\n",
    "\n",
    "As outliers were removed the training and test scores were ameliorated, giving increased confidence in the effect/importance of the coefficients (variables).\n",
    "\n",
    "<img src = \"/Final_Movies/readme/ElasticNet_Models_with_Various_Preprocessing_Methods.png\" width=\"700\">\n",
    "\n",
    "The root mean squared error was also used as a metric to compare the models' performance.\n",
    "\n",
    "<img src = \"/Final_Movies/readme/ElasticNet_Models_with_Various_Preprocessing_Methods_rmse.png\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d852d",
   "metadata": {},
   "source": [
    "## Classification Modelling\n",
    "ElasticNet Logistic Regression, Decision Tree Classification, XGBoost (ensemble method) and a Support Vector Machine were used to predict whether films would make a profit or not. Each film performed better than randomly guessing if the film would make a profit (above the baseline accuracy) with the best being an ElasticNet logistic regression model (l1_ratio of 0.21 , C of 51.79). The ElasticNet model had a cross validated accuacy of ~0.66 and had a similar score to the Support Vetor Machine.\n",
    "\n",
    "\n",
    "<img src = \"/Final_Movies/readme/regression_models_original.png\" width=\"700\">\n",
    "\n",
    "\n",
    "A multi-class classification model was also carried out. The ROI variable was split into quintiles (baseline accuracy of 0.20) and an ElastiNet Logistic Regression produced an accuracy of 0.33.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dca5ac",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "- Use an alternative data source for film budgets and revenues (e.g. the-numbers.com). \n",
    "\n",
    "- Instead of looking at the impact of all actors/directors, creating a variable that confirms if the actors/directors contained in the film are popular at that current point in time will be more beneficial for a productionisable model.\n",
    "\n",
    "- Additional feature - from_bestselling_book? - If the story was based off a bestselling book, would that increase the chances of higher ROI?\n",
    "\n",
    "- Using statsmodels to be able to see the significance of the features in the model.\n",
    "\n",
    "\n",
    "## Notebook Order\n",
    "1. move_scraping_final.ipynb  \n",
    "2. cleaning & EDA.ipynb  / BLURB SPACY ANALYSIS.ipynb\n",
    "3. modelling to see feature importance using regression techniques.ipynb\n",
    "4. classifying_profit_for_comparison_against_the_regression_models.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
